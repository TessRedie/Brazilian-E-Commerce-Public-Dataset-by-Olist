{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer purchase prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine orders , reviews, payments dataset with customer dataset and dropping unwanted columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "item=pd.read_csv(\"olist_order_items_dataset.csv\")\n",
    "order=pd.read_csv(\"olist_orders_dataset.csv\")\n",
    "product=pd.read_csv(\"olist_products_dataset.csv\")\n",
    "customer=pd.read_csv(\"olist_customers_dataset.csv\")\n",
    "review=pd.read_csv(\"olist_order_reviews_dataset.csv\") \n",
    "payment=pd.read_csv(\"olist_order_payments_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.merge(customer.drop(columns=['customer_zip_code_prefix']),order[['customer_id','order_id','order_purchase_timestamp']],on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df1,review[['order_id','review_score']],on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paid = payment[['order_id','payment_value']].groupby('order_id').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df2,paid,on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## making purchase date in datetime format\n",
    "df3['order_purchase_timestamp']=pd.to_datetime(df3['order_purchase_timestamp']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2017-05-16\n",
       "1        2018-01-12\n",
       "2        2018-05-19\n",
       "3        2018-03-13\n",
       "4        2018-07-29\n",
       "            ...    \n",
       "99994    2018-04-07\n",
       "99995    2018-04-04\n",
       "99996    2018-04-08\n",
       "99997    2017-11-03\n",
       "99998    2017-12-19\n",
       "Name: order_purchase_timestamp, Length: 99999, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['order_purchase_timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to sperate out 180 days (last 6 months) from the maximum day of purchase by customers out of the dataset. 2018/4 to 2018/10.\n",
    "## We are using that data to predict whether the customer made a purchase in that period. We are going to use data until 2018/4 to make that prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_days_for_purchase=180\n",
    "max_date_in_data= df3['order_purchase_timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date_in_data= df3['order_purchase_timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2016, 9, 4)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_date_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2018, 10, 17)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_date=max_date_in_data -timedelta(days=number_of_days_for_purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2018, 4, 20)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full=df3[df3['order_purchase_timestamp']<=data_split_date]\n",
    "df_last=df3[df3['order_purchase_timestamp']>data_split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_180 =pd.DataFrame({'customer_unique_id':df3['customer_unique_id'].values.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_180=df_last_180.merge(df_last.groupby(['customer_unique_id'])['payment_value'].sum().reset_index(),how='outer',on='customer_unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_180.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_180['purchased']=np.where(df_last_180['payment_value']>0, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>157.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>252.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_unique_id  payment_value  purchased\n",
       "0  861eff4711a542e4b93843c6dd7febb0           0.00          0\n",
       "1  290c77bc529b7ac935b93aa66c333dc3           0.00          0\n",
       "2  060e732b5b29e8181a18229c7b0b2b5e         157.73          1\n",
       "3  259dac757896d24d7702b9acbbff3f3c           0.00          0\n",
       "4  345ecd01c38d18a9036ed96c73b8d066         252.25          1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_last_180.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The customers who bought items in that 6 months were given 1 and others were given 0. these values will act as binary classification for our prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total amount per customer\n",
    "tot_Amount=df_full.groupby('customer_unique_id')['payment_value'].sum().reset_index().rename(columns={'payment_value':'total_amount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## average review given\n",
    "avg_review=df_full.groupby('customer_unique_id')['review_score'].mean().reset_index().rename(columns={'review_score':'avg_review'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## months between first purchase and today\n",
    "min_max_date=df_full.groupby('customer_unique_id')['order_purchase_timestamp'].agg([min,max])\n",
    "min_max_date['diff_first_today']=(datetime.today().date()-min_max_date['min']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## months from first to last purchase\n",
    "min_max_date['max']=pd.to_datetime(min_max_date['max'])\n",
    "min_max_date['min']=pd.to_datetime(min_max_date['min'])\n",
    "min_max_date['diff_first_last']=(min_max_date['max']-min_max_date['min']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recency of Sales \n",
    "max_date=df_full['order_purchase_timestamp'].max()\n",
    "\n",
    "min_max_date['recency']=(np.datetime64(max_date)-min_max_date['max'])/np.timedelta64(1, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Frequency of Sales\n",
    "frequency=df_full.groupby('customer_unique_id')['order_id'].count().reset_index().rename(columns={'order_id':'frequency'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## joining all the engineered features\n",
    "dataset=pd.merge(tot_Amount,avg_review,on='customer_unique_id')\n",
    "dataset=pd.merge(dataset,min_max_date,on='customer_unique_id')\n",
    "dataset=pd.merge(dataset,frequency,on='customer_unique_id')\n",
    "dataset=pd.merge(dataset,df_full[['customer_unique_id','customer_city','customer_state']],on='customer_unique_id')\n",
    "dataset.drop(['min','max'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "### label encoding city and state names\n",
    "encoder=LabelEncoder()\n",
    "dataset['customer_city']=encoder.fit_transform(dataset['customer_city'])\n",
    "dataset['customer_state']=encoder.fit_transform(dataset['customer_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "##merging with the label dataset we have created \n",
    "dataset_full=dataset.merge(df_last_180[['customer_unique_id','purchased']],on='customer_unique_id')\n",
    "dataset_full.drop(columns='customer_unique_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are going to do binary classification to predict whether a customer will purchase within the next 6 months Since this is a classification problem we use several models here , For comparing the models we use metrics like r2 score and accuracy score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear Regression\n",
    "2. Random Forest Classifier\n",
    "3. Extra Trees Classifier\n",
    "4. Gradient Boost Classifier\n",
    "5. K nearest nerighbour Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score,accuracy_score,classification_report\n",
    "# Splitting data into training/testing\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting to train and test dataset\n",
    "X_train,X_test,y_train,y_test=train_test_split(dataset_full.iloc[:,:-1],dataset_full.iloc[:,-1], test_size=0.2, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating gini scores for the models\n",
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1/n_samples, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred/G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate several ml models by training on training set and testing on testing set\n",
    "def evaluate(X_train, X_test, y_train, y_test):\n",
    "    # Names of models\n",
    "    model_name_list = ['Linear Regression',\n",
    "                      'Random Forest', 'Extra Trees',\n",
    "                       'Gradient Boosted','KNeighbors']\n",
    "\n",
    "    \n",
    "    # Instantiate the models\n",
    "    model1 = LinearRegression()\n",
    "    model3 = RandomForestClassifier(n_estimators=50)\n",
    "    model4 = ExtraTreesClassifier(n_estimators=50)\n",
    "    model6 = GradientBoostingClassifier(n_estimators=20)\n",
    "    model7= KNeighborsClassifier(n_neighbors = 5)\n",
    "    \n",
    "    # Dataframe for results\n",
    "    results = pd.DataFrame(columns=['r2', 'accuracy','gini'], index = model_name_list)\n",
    "    \n",
    "    # Train and predict with each model\n",
    "    for i, model in enumerate([model1, model3, model4, model6,model7]):\n",
    "   \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "               \n",
    "        # Metrics\n",
    "        r2 = r2_score(y_test,predictions)\n",
    "        preds=np.where(predictions>0.5,1,0)\n",
    "        accuracy = accuracy_score(y_test,preds)\n",
    "        gini=Gini(y_test,preds)\n",
    "        \n",
    "        # Insert results into the dataframe\n",
    "        model_name = model_name_list[i]\n",
    "        results.loc[model_name, :] = [r2, accuracy,gini]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=evaluate(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.051544</td>\n",
       "      <td>0.977076</td>\n",
       "      <td>-0.0151789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.835912</td>\n",
       "      <td>0.996325</td>\n",
       "      <td>0.862908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Trees</th>\n",
       "      <td>0.83035</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.883488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted</th>\n",
       "      <td>0.0961274</td>\n",
       "      <td>0.979755</td>\n",
       "      <td>0.134211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.338087</td>\n",
       "      <td>0.985174</td>\n",
       "      <td>0.442184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          r2  accuracy       gini\n",
       "Linear Regression   0.051544  0.977076 -0.0151789\n",
       "Random Forest       0.835912  0.996325   0.862908\n",
       "Extra Trees          0.83035    0.9962   0.883488\n",
       "Gradient Boosted   0.0961274  0.979755   0.134211\n",
       "KNeighbors          0.338087  0.985174   0.442184"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As r2 score reaches 1, the model is much capable of explaining the variance in purchase probability prediction of the customers. So Random Forest Classifier is the best classifier for the prediction.\n",
    "\n",
    "### The gini coefficient of the forest classifier and Extratrees classifier is closer to one, meaning there is inequality in the predicted values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
